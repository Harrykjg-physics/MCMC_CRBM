{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ising CRBM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielalcalde/MCMC_CRBM/blob/master/Ising_CRBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amXB-OcpSa1R",
        "colab_type": "text"
      },
      "source": [
        "# Simulating the Ising model using an CRBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0xxh6USSodO",
        "colab_type": "text"
      },
      "source": [
        "## Abstract:\n",
        "Machine learning is becoming widely used in analyzing the thermodynamics of many-body condensed matter systems.\n",
        "Restricted Boltzmann Machine (RBM) aided Montecarlo simulations have sparked interest recently as they manage to speed up classical Monte Carlo simulations.\n",
        "Here we employ the Convolutional Restricted Boltzmann Machine (CRBM) method and show that its use helps to reduce the number of parameters to be learned drastically by taking advantage of translation invariance. Furthermore, we show that it is possible to train the CRBM at smaller lattice sizes, and apply it to bigger lattice sizes. To demonstrate the efficiency of CRBM we apply it to the paradigmatic  Ising and Kitaev models in two dimensions.\n",
        "\n",
        "## Paper:\n",
        "paper link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaiBKOtWTBEV",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "This Notebook is intended as an educational tool for the use of Convolutional Restricted Boltzmann Machines in classical Montecarlo simulations. The code for the paper was written with the library Theano, which will no longer be updated, that is why we have chosen to present the main concept in TensorFlow. Specifically, this notebook only tackles the Ising model. As there is only the nearest neighbor interaction, we can teach the CRBM using $3\\times3$ states, this has as a consequence that we are able to generate all possible states $2^{3\\times3}= 512$ and learn the energy function from them. So no Metropolis is necessary, and no sampling of the CRBM while training is necessary. Also contrary to the main work, for simplicity, no correction step or parallel tempering is introduced. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t5AMJk__vdw",
        "colab_type": "text"
      },
      "source": [
        "# Installing tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqVmIoHumhCe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "30a0273b-7249-4e10-8746-a367e97f3d3c"
      },
      "source": [
        "\"\"\"\n",
        "### install necessary packages if in colab\n",
        "def run_subprocess_command(cmd):\n",
        "    process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
        "    for line in process.stdout:\n",
        "        print(line.decode().strip())\n",
        "\n",
        "\n",
        "import sys, subprocess\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "colab_requirements = [\"pip install tensorflow-gpu==2.1.0\"]\n",
        "if IN_COLAB:\n",
        "    for i in colab_requirements:\n",
        "        run_subprocess_command(i)\n",
        "\"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\n### install necessary packages if in colab\\ndef run_subprocess_command(cmd):\\n    process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\\n    for line in process.stdout:\\n        print(line.decode().strip())\\n\\n\\nimport sys, subprocess\\n\\nIN_COLAB = \"google.colab\" in sys.modules\\ncolab_requirements = [\"pip install tensorflow-gpu==2.1.0\"]\\nif IN_COLAB:\\n    for i in colab_requirements:\\n        run_subprocess_command(i)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzkLSnOF_4EG",
        "colab_type": "text"
      },
      "source": [
        "# Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTbdHbRCoJzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxU5e0nT5vzC",
        "colab_type": "text"
      },
      "source": [
        "Set seed for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr4p5UEh5kWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adjL1Ta-4yjG",
        "colab_type": "text"
      },
      "source": [
        "Accuracy used for training and numerics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mYviS_74wT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "floatX = np.float32"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdJQe7e7PmE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t0 = time.time()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6CGNL5T__7Q",
        "colab_type": "text"
      },
      "source": [
        "# Helping functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMdm-89o52rP",
        "colab_type": "text"
      },
      "source": [
        "Tensorflow has no implementation of the binomial function. With help of random.uniform the beahviour can be replicated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuZ3rWnuorPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binomial(means):\n",
        "    return (tf.sign(means - tf.random.uniform(tf.shape(means))) + 1 ) / 2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRYigXZ33_SS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1981e572-84ec-4fe7-bb74-6cd40a882c02"
      },
      "source": [
        "binomial(np.array([0.5, 0.5, 0.1, 0.9]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8rR10bN6WBI",
        "colab_type": "text"
      },
      "source": [
        "This functions creates periodic padding so that the convolution has periodic boundary conditions. When performing the transposed convolution step the padding is placed at the oposite side."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWbNnXjOng1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "764dd0d1-5f13-45b5-dc35-b193c83362af"
      },
      "source": [
        "def periodic_padding(x, filter_size=2, deconv=False):\n",
        "    '''\n",
        "    x: shape (batch_size, d1, d2)\n",
        "    return x padded with periodic boundaries. i.e. torus or donut\n",
        "    '''\n",
        "    pad_r = filter_size // 2\n",
        "    pad_l = filter_size - pad_r - 1\n",
        "    \n",
        "    d1, d2 = x.shape[1:3]\n",
        "    \n",
        "    # When deconvolving the pading should reverses\n",
        "    if deconv:\n",
        "        p = pad_r\n",
        "        pad_r = pad_l\n",
        "        pad_l = p   \n",
        "\n",
        "    top_left = x[:, d1 - pad_l:, d2 - pad_l:]\n",
        "    top_center = x[:, d1 - pad_l:, :]\n",
        "    top_right = x[:, d1 - pad_l:, :pad_r]\n",
        "\n",
        "    middle_left = x[:, :, d2 - pad_l:]\n",
        "    middle_center = x\n",
        "    middle_right = x[:, :, :pad_r]\n",
        "\n",
        "    bottom_left = x[:, :pad_r, d2 - pad_l:]\n",
        "    bottom_center = x[:, :pad_r, :]\n",
        "    bottom_right = x[:, :pad_r, :pad_r]\n",
        "    \n",
        "    top = tf.concat([top_left, top_center, top_right], axis=2)\n",
        "    middle = tf.concat([middle_left, middle_center, middle_right], axis=2)\n",
        "    bottom = tf.concat([bottom_left, bottom_center, bottom_right], axis=2)\n",
        "    padded_x = tf.concat([top, middle, bottom], axis=1)\n",
        "    return padded_x\n",
        "\n",
        "a = tf.Variable(np.arange(4 * 4).reshape(1, 4, 4))\n",
        "print(a[0].numpy())\n",
        "print()\n",
        "print(periodic_padding(a)[0].numpy())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  1  2  3]\n",
            " [ 4  5  6  7]\n",
            " [ 8  9 10 11]\n",
            " [12 13 14 15]]\n",
            "\n",
            "[[ 0  1  2  3  0]\n",
            " [ 4  5  6  7  4]\n",
            " [ 8  9 10 11  8]\n",
            " [12 13 14 15 12]\n",
            " [ 0  1  2  3  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ba-8XzQve8c",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85mAzBWlt7p7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_int(x):\n",
        "    if x =='0' or x == '1': return int(x)\n",
        "    else: return 0\n",
        "\n",
        "#This will generate all posible LXL matrices with {0,1}^(LXL) don't use with more then L=4\n",
        "def bit_string(L):\n",
        "    maxim = 2 ** (L ** 2)\n",
        "    a = np.asarray([[to_int(x) for x in list(('{0:' + str(L ** 2) + 'b}').format(i))] for i in range(maxim)], dtype=floatX)\n",
        "    return a.reshape(2 ** (L ** 2), L, L)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m19Njkt2AJsT",
        "colab_type": "text"
      },
      "source": [
        "Generate all posible $3\\times3$ states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5IEPtsTvUIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0d23749d-5610-49a2-e867-71914ca955df"
      },
      "source": [
        "states_train = bit_string(3)[:, :, :, None]\n",
        "states_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 3, 3, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOS0L2tAATVe",
        "colab_type": "text"
      },
      "source": [
        "Generate a random test set of lattice size $L=50$ to evaluate if the CRBM matches the Ising model at large lattice sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4t-Mm4E1ur4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a3505984-52e0-4e81-eed4-2da034f00f0d"
      },
      "source": [
        "L = 50\n",
        "states_test = np.asarray(np.random.binomial(size=(4 * 10 ** 3, L, L, 1), p=0.5, n=1), dtype=floatX)\n",
        "states_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 50, 50, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k24jeiSitDR_",
        "colab_type": "text"
      },
      "source": [
        "Define the energy of given state for the Ising model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1CTzY8LvrPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ising_energy(states):\n",
        "    states = 2 * states - 1\n",
        "\n",
        "    nb = np.roll(states, shift=-1, axis=1) + np.roll(states, shift=-1, axis=2)\n",
        "\n",
        "    return -np.sum(states * nb, axis=(1, 2, 3))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31kyXyzxAteM",
        "colab_type": "text"
      },
      "source": [
        "For now we will only consider the case $T=1$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DwA8L7N2XbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = 1."
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoCi0HL2A16p",
        "colab_type": "text"
      },
      "source": [
        "The physical energy is computed for train and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ny3qOL3vl3O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9101a2d6-9b96-490f-aab0-d3cbbd7b305b"
      },
      "source": [
        "E_phys_train = ising_energy(states_train)\n",
        "E_phys_test = ising_energy(states_test)\n",
        "E_phys_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ0t1lhZBB4c",
        "colab_type": "text"
      },
      "source": [
        "The CRBM will be trained by batches of 32 states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSZRLeNDwxuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2649ec5c-3cf1-47f6-e0b3-6ff17c0b680e"
      },
      "source": [
        "TRAIN_BUF = E_phys_train.shape[0]\n",
        "BATCH_SIZE = 2 ** 5\n",
        "N_TRAIN_BATCHES = TRAIN_BUF// BATCH_SIZE\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((states_train, E_phys_train)).shuffle(TRAIN_BUF).batch(BATCH_SIZE)\n",
        "BATCH_SIZE"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BzB92R0zgqs",
        "colab_type": "text"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxSkWptE0hXI",
        "colab_type": "text"
      },
      "source": [
        "Initialize the kernel W with filter_dims=(filter_number, filter_size) and both biases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0H-WBKOx1Lv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e2ac3ed3-958b-4fcf-dc25-3aefb9a5eb99"
      },
      "source": [
        "filter_dims = (2, 2)\n",
        "filter_shape = (filter_dims[1], filter_dims[1], 1, filter_dims[0])\n",
        "\n",
        "\n",
        "multi = np.prod(filter_shape)\n",
        "W_np = np.asarray(np.random.randn(*filter_shape) * np.sqrt(2 / multi), dtype=floatX)\n",
        "\n",
        "W = tf.Variable(W_np * 2)\n",
        "\n",
        "vbias = tf.Variable(np.zeros(1, dtype=floatX))\n",
        "hbias = tf.Variable(np.zeros(filter_dims[0], dtype=floatX))\n",
        "W, vbias, hbias = crbm.W, crbm.vbias, crbm.hbias\n",
        "print(\"vbias.shape:\", vbias.shape)\n",
        "print(\"hbias.shape:\", hbias.shape)\n",
        "print(\"W.shape:\", W.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vbias.shape: (1,)\n",
            "hbias.shape: (2,)\n",
            "W.shape: (2, 2, 1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6CTcpub1Dd8",
        "colab_type": "text"
      },
      "source": [
        "The negative log likelihood also called free energy: \\\\\n",
        "$F(v) = -v_\\text{bias} \\sum_{i,j} v_{ij} -\\sum_{i,j} \\log(1+e^{\\sum_{k} (v*W^k)_{ij} +h^k_\\text{bias}})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYuxQcKzx5cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def n_log_like(v):\n",
        "    input4D = periodic_padding(v, filter_dims[1])\n",
        "    filters4D = W\n",
        "\n",
        "    # Convolution\n",
        "    out = tf.nn.conv2d(input4D, filters4D, strides=1, padding=\"VALID\")\n",
        "    out = hbias[None, None, None, :] + out\n",
        "\n",
        "    # Same as softplus(x)=log(1 + exp(x))\n",
        "    hidden_term_not = tf.math.softplus(out)\n",
        "    hidden_term = tf.reduce_sum(hidden_term_not, axis=(1, 2, 3))\n",
        "\n",
        "    visible_term = tf.reduce_sum(v, axis=(1, 2)) * vbias[None, :]\n",
        "    visible_term = tf.reduce_sum(visible_term, axis=1)\n",
        "\n",
        "    return -hidden_term - visible_term"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXdCNfJ_1dGb",
        "colab_type": "text"
      },
      "source": [
        "$P(h|x): x \\rightarrow h$ \\\\\n",
        "$P(h^k_{ij}=1|v)=\\sigma((W^k * v)_{ij} + h_\\text{bias}^k) ) $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EPUk1rvyAI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "592b1b0c-17ac-4e27-dcb3-75aa594ab466"
      },
      "source": [
        "def prop_vis_to_hid(v):\n",
        "    input4D = periodic_padding(v, filter_dims[1])\n",
        "    filters4D = W\n",
        "\n",
        "    # Convolution\n",
        "    out = tf.nn.conv2d(input4D, filters4D, strides=1, padding=\"VALID\")\n",
        "\n",
        "    out += hbias[None, None, None, :]\n",
        "\n",
        "    mean_activation = tf.math.sigmoid(out)\n",
        "    return binomial(mean_activation), mean_activation\n",
        "\n",
        "h, act = prop_vis_to_hid(states_train[100][None])\n",
        "print(\"visible_shape:\", states_train[100][None].shape)\n",
        "print(\"hidden_shape:\", h.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "visible_shape: (1, 3, 3, 1)\n",
            "hidden_shape: (1, 3, 3, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxXeic0n2Cft",
        "colab_type": "text"
      },
      "source": [
        "$P(x|h): h \\rightarrow x$ \\\\\n",
        "$P(v_{ij}=1|h)=\\sigma((\\sum_k \\bar{W}^k * h^k)_{ij} +v_\\text{bias}))$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0s652fiyHR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prop_hid_to_vis(h):\n",
        "    input4D = periodic_padding(h, filter_dims[1], deconv=True)\n",
        "    filters4D = tf.transpose(W[::-1, ::-1], [0, 1, 3, 2])\n",
        "\n",
        "    # Convolution\n",
        "    out = tf.nn.conv2d(input4D, filters4D, strides=1, padding=\"VALID\")\n",
        "\n",
        "    out += vbias[None, None, None, :]\n",
        "\n",
        "    mean_activation = tf.math.sigmoid(out)\n",
        "    return binomial(mean_activation), mean_activation"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKCCahXU2Nj_",
        "colab_type": "text"
      },
      "source": [
        "$P(x'|x): x \\rightarrow h\\rightarrow x'$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDEsrO92yN3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gibbs(state):\n",
        "    h, h_act = prop_vis_to_hid(state)\n",
        "    x, x_act = prop_vis_to_hid(h)\n",
        "    return x, x_act, h, h_act"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxzoSUrpHMrP",
        "colab_type": "text"
      },
      "source": [
        "Plot the intermidiary states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXivV6u7_NEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def arrow(ax):\n",
        "    ax.arrow(0., 0.5, 0.5, 0, head_width = 0.2, width = 0.05)\n",
        "    ax.axis('off')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjw_WiaXyTKP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "611d7e2c-3a64-47e3-dfc1-7067ae00a2b1"
      },
      "source": [
        " x_old = np.asarray(np.random.binomial(n=1, p=0.1, size=(1, 5, 5, 1)), dtype=floatX)\n",
        " x, x_act, h, h_act = gibbs(x_old)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=3, ncols=9, figsize=(9 * 2, 3 * 2))\n",
        "axes[1, 0].imshow(x_old[0, :, :, 0], vmin=0, vmax=1, cmap=\"gray\")\n",
        "axes[1, 0].set_xlabel(\"x\", fontsize=20)\n",
        "arrow(axes[1, 1])\n",
        "\n",
        "# Remove unwanted plots\n",
        "for ij in [(0,0), (2,0), (0,1), (2,1), (1,2), (1,3), (1, 4), (0,5), (2, 5), (0,6), (2, 6), (0, 7), (2, 7), (0, 8), (2, 8)]:\n",
        "    axes[ij[0], ij[1]].set_visible(False)\n",
        "\n",
        "for i in range(2):\n",
        "    axes[2*i, 2].imshow(h_act[0, :, :, i], vmin=0, vmax=1, cmap=\"gray\")\n",
        "    axes[2*i, 2].set_xlabel(f'$P(h^{i}|x)$', fontsize=20)\n",
        "    \n",
        "    arrow(axes[2*i, 3])\n",
        "\n",
        "    axes[2*i, 4].imshow(h[0, :, :, i], vmin=0, vmax=1, cmap=\"gray\")\n",
        "    axes[2*i, 4].set_xlabel(f'$h^{i}$', fontsize=20)\n",
        "    \n",
        "       \n",
        "\n",
        "arrow(axes[1, 5])\n",
        "axes[1, 6].imshow(x_act[0, :, :, 0], vmin=0, vmax=1, cmap=\"gray\")\n",
        "axes[1, 6].set_xlabel(\"P(x'|h)\", fontsize=20)\n",
        "\n",
        "arrow(axes[1, 7])\n",
        "\n",
        "axes[1, 8].imshow(x[0, :, :, 0], vmin=0, vmax=1, cmap=\"gray\")\n",
        "axes[1, 8].set_xlabel(\"x'\", fontsize=20)\n",
        "# Deactivate axes\n",
        "for j in range(9):\n",
        "    for i in range(3):\n",
        "        axes[i, j].set_xticks([])\n",
        "        axes[i, j].set_yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x432 with 27 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvZzNjW_2W2_",
        "colab_type": "text"
      },
      "source": [
        "$\\text{diff}(x) = E(x) - F(x)$ \\\\\n",
        "$C = \\frac{1}{M} \\sum_x \\text{diff}(x)$ \\\\\n",
        "$\\text{loss} = \\sum_x (\\text{diff}(x) - C)^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "expppT3Qyc48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def compute_loss(x, nll_phys):\n",
        "    nll_crbm = n_log_like(x)\n",
        "\n",
        "    diff = nll_phys - nll_crbm\n",
        "    C = tf.reduce_mean(diff)\n",
        "\n",
        "    loss = tf.reduce_mean((diff - C) ** 2)\n",
        "    return loss"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tazcvUJ3b4D",
        "colab_type": "text"
      },
      "source": [
        "Initialize the adam optimizer, compute the gradients and apply them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ctvr0eLymUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = tf.keras.optimizers.Adam()\n",
        "def compute_grad(x, nll_phys):\n",
        "    ### pass through network\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = compute_loss(x, nll_phys)\n",
        "\n",
        "    # compute the grad\n",
        "    grad = tape.gradient(loss, params)\n",
        "    return grad, loss\n",
        "\n",
        "@tf.function\n",
        "def train(x, nll_phys):\n",
        "    grad, loss = compute_grad(x, nll_phys)\n",
        "\n",
        "    opt.apply_gradients(zip(grad, params))\n",
        "    return loss"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2mNJF1ixnN4",
        "colab_type": "text"
      },
      "source": [
        "Everything combined in one class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu2rPLnOmrjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CRBM:\n",
        "        def __init__(\n",
        "        self,\n",
        "        filter_dims=(2, 2),\n",
        "        opt=None\n",
        "\n",
        "    ):\n",
        "            assert len(filter_dims) == 2\n",
        "            if opt is None:\n",
        "                opt = tf.keras.optimizers.Adam()\n",
        "                \n",
        "            self.opt = opt\n",
        "            \n",
        "            self.filter_shape = (filter_dims[1], filter_dims[1], 1, filter_dims[0])\n",
        "            self.filter_dims = filter_dims\n",
        "\n",
        "\n",
        "            multi = np.prod(self.filter_shape)\n",
        "            W_np = np.asarray(np.random.randn(*self.filter_shape) * np.sqrt(2 / multi), dtype=floatX)\n",
        "\n",
        "            W = tf.Variable(W_np)\n",
        "\n",
        "            vbias = tf.Variable(np.zeros(1, dtype=floatX))\n",
        "            hbias = tf.Variable(np.zeros(filter_dims[0], dtype=floatX))\n",
        "\n",
        "            self.W = W\n",
        "            self.hbias = hbias\n",
        "            self.vbias = vbias\n",
        "\n",
        "\n",
        "            # Learning parameters\n",
        "            self.params = [self.W, self.vbias, self.hbias]\n",
        "\n",
        "\n",
        "        def n_log_like(self, v):\n",
        "            input4D = periodic_padding(v, self.filter_dims[1])\n",
        "            filters4D = self.W\n",
        "\n",
        "            # Convolution\n",
        "            out = tf.nn.conv2d(input4D, filters4D, strides=1, padding=\"VALID\")\n",
        "            out = self.hbias[None, None, None, :] + out\n",
        "\n",
        "            # Same as softplus(x)=log(1 + exp(x))\n",
        "            hidden_term_not = tf.math.softplus(out)\n",
        "            hidden_term = tf.reduce_sum(hidden_term_not, axis=(1, 2, 3))\n",
        "\n",
        "            visible_term = tf.reduce_sum(v, axis=(1, 2)) * self.vbias[None, :]\n",
        "            visible_term = tf.reduce_sum(visible_term, axis=1)\n",
        "\n",
        "            return -hidden_term - visible_term\n",
        "\n",
        "        def prop_vis_to_hid(self, v):\n",
        "            input4D = periodic_padding(v, self.filter_dims[1])\n",
        "            filters4D = self.W\n",
        "            \n",
        "            # Convolution\n",
        "            out = tf.nn.conv2d(input4D, filters4D, strides=1, padding=\"VALID\")\n",
        "            \n",
        "            out += self.hbias[None, None, None, :]\n",
        "            \n",
        "            mean_activation = tf.math.sigmoid(out)\n",
        "            return binomial(mean_activation)\n",
        "            \n",
        "        \n",
        "        def prop_hid_to_vis(self, h):\n",
        "            input4D = periodic_padding(h, self.filter_dims[1], deconv=True)\n",
        "            filters4D = tf.transpose(self.W[::-1, ::-1], [0, 1, 3, 2])\n",
        "\n",
        "            # Convolution\n",
        "            out = tf.nn.conv2d(input4D, filters4D, strides=1, padding=\"VALID\")\n",
        "            \n",
        "            out += self.vbias[None, None, None, :]\n",
        "            \n",
        "            mean_activation = tf.math.sigmoid(out)\n",
        "            return binomial(mean_activation)\n",
        "        \n",
        "        @tf.function\n",
        "        def gibbs(self, state):\n",
        "            return self.prop_hid_to_vis(self.prop_vis_to_hid(state))\n",
        "        \n",
        "        \n",
        "        @tf.function\n",
        "        def gibbs_k(self, state, k=1):\n",
        "            \n",
        "            i = tf.constant(0)\n",
        "            cond = lambda i, state: tf.less(i, k)\n",
        "\n",
        "            def operation(i, state):\n",
        "                i += 1\n",
        "                state = self.gibbs(state)\n",
        "                return i, state\n",
        "\n",
        "            _, state = tf.while_loop(cond, operation, [i, state])\n",
        "            \n",
        "            return state\n",
        "        \n",
        "        @tf.function\n",
        "        def compute_loss(self, x, nll_phys):\n",
        "            nll_crbm = self.n_log_like(x)\n",
        "\n",
        "            diff = nll_phys - nll_crbm\n",
        "            C = tf.reduce_mean(diff)\n",
        "            \n",
        "            loss = tf.reduce_mean((diff - C) ** 2)\n",
        "            return loss\n",
        "        \n",
        "        def compute_grad(self, x, nll_phys):\n",
        "            # compute the grad\n",
        "\n",
        "            ### pass through network\n",
        "            with tf.GradientTape() as tape:\n",
        "                loss = self.compute_loss(x, nll_phys)\n",
        "\n",
        "            grad = tape.gradient(loss, self.params)\n",
        "            return grad, loss\n",
        "    \n",
        "\n",
        "        @tf.function\n",
        "        def train(self, x, nll_phys):\n",
        "            grad, loss = self.compute_grad(x, nll_phys)\n",
        "\n",
        "            self.opt.apply_gradients(zip(grad, self.params))\n",
        "            return loss"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMFUHQ7hyNXR",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ylnigpuBSB9",
        "colab_type": "text"
      },
      "source": [
        "We create an CRBM object and train it. One can see that both the train_loss and the test_loss decrease simulaniously. The expected difference between the two losses should be around $\\frac{t_{test}}{t_{train}}=\\frac{N_{test}^2}{N^2_{train}}=\\frac{50^2}{3^2}=277.77$. Note that our objective is that $F_{RBM}(x)=\\beta E(x)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpvy_HS-vrMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crbm = CRBM(filter_dims=(2, 2))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Luj353ygYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train = []\n",
        "loss_test = []\n",
        "epoch = 0"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmVULw63xiGi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "12cb67cd-391d-42d6-92b1-1293536d21d9"
      },
      "source": [
        "%%time\n",
        "l_train = 10 ** 9\n",
        "l_test = 10 ** 9\n",
        "\n",
        "while l_train > 10 ** -4:\n",
        "    # train\n",
        "    l_train = 0\n",
        "    \n",
        "    for train_s, train_E in train_dataset:\n",
        "        l_train += crbm.train(train_s, train_E / temp)\n",
        "    \n",
        "    \n",
        "    l_train = l_train / N_TRAIN_BATCHES\n",
        "    #for test_x, test_y in tqdm(test_ds, total=N_TEST_BATCHES):\n",
        "    #l_test, acc_test = mps.compute_loss_accuracy(x_test, y_test)\n",
        "        \n",
        "    # plot results\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "        l_test = crbm.compute_loss(states_test, E_phys_test / temp)\n",
        "        \n",
        "        loss_train.append(l_train) \n",
        "        loss_test.append(l_test)\n",
        "        \n",
        "        display.clear_output()\n",
        "\n",
        "        print(\n",
        "            f\"Epoch: {epoch} | loss test: {loss_test[-1]}| loss train: {loss_train[-1]}| ltest/ltrain: {loss_test[-1]/loss_train[-1]}\"\n",
        "        )\n",
        "        plt.plot(loss_train)\n",
        "        plt.plot(loss_test)\n",
        "        plt.yscale(\"log\")\n",
        "        plt.show()\n",
        "    epoch += 1"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4000 | loss test: 0.03208981826901436| loss train: 0.00011812156299129128| ltest/ltrain: 271.6677551269531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-6ba05798a8e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l_train = 10 ** 9\\nl_test = 10 ** 9\\n\\nwhile l_train > 10 ** -4:\\n    # train\\n    l_train = 0\\n    \\n    for train_s, train_E in train_dataset:\\n        l_train += crbm.train(train_s, train_E / temp)\\n    \\n    \\n    l_train = l_train / N_TRAIN_BATCHES\\n    #for test_x, test_y in tqdm(test_ds, total=N_TEST_BATCHES):\\n    #l_test, acc_test = mps.compute_loss_accuracy(x_test, y_test)\\n        \\n    # plot results\\n    \\n    if epoch % 100 == 0:\\n        l_test = crbm.compute_loss(states_test, E_phys_test / temp)\\n        \\n        loss_train.append(l_train) \\n        loss_test.append(l_test)\\n        \\n        display.clear_output()\\n\\n        print(\\n            f\"Epoch: {epoch} | loss test: {loss_test[-1]}| loss train: {loss_train[-1]}| ltest/ltrain: {loss_test[-1]/loss_train[-1]}\"\\n        )\\n        plt.plot(loss_train)\\n        plt.plot(loss_test)\\n        plt.yscale(\"log\")\\n        plt.show()\\n    epoch += 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBaalL7QRmEn",
        "colab_type": "text"
      },
      "source": [
        "The learned convolutional filters show the effective interaction between nearest neighbours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBc3oN6q41eB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = crbm.W.numpy()\n",
        "vmax = np.max(abs(W))\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "\n",
        "axes[0].imshow(W[:, :,0, 0], vmin =-vmax, vmax=vmax, cmap=\"seismic\")\n",
        "axes[1].imshow(W[:,: ,0, 1], vmin =-vmax, vmax=vmax, cmap=\"seismic\")\n",
        "\n",
        "# Deactivate axes\n",
        "for j in range(2):\n",
        "    axes[j].set_xticks([])\n",
        "    axes[j].set_yticks([])\n",
        "    axes[j].set_xlabel(f'$W^{j}$', fontsize=20)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mZoKqjr7uVT",
        "colab_type": "text"
      },
      "source": [
        "# Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVHIsquKZoh1",
        "colab_type": "text"
      },
      "source": [
        "A state with $L=40$ is updated $5*10 ^4$ times using gibbs sampling.  Because the temperature T=1, is well bellow the critical temperature TC=2.269 it converges to the ground state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30z8c8PT7JLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L = 40\n",
        "states = tf.random.uniform((1, L, L, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsODKWM66otO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 5 * 10 ** 4\n",
        "Es = []\n",
        "for i in range(epochs):\n",
        "    states = crbm.gibbs(states)\n",
        "    Es.append(ising_energy(states)[0])\n",
        "    \n",
        "    if i % 1000 == 0:\n",
        "        display.clear_output(wait=True)\n",
        "        fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(15, 5))\n",
        "\n",
        "        axes[0].imshow(states.numpy()[0, :,:, 0], vmin=0, vmax=1, cmap=\"gray\")\n",
        "        axes[0].set_xticks([])\n",
        "        axes[0].set_yticks([])\n",
        "        axes[j].set_xlabel(f'sate', fontsize=20)\n",
        "\n",
        "\n",
        "        axes[1].plot(Es)\n",
        "        axes[1].plot([0, len(Es)], [-2 * L**2, -2 * L**2])\n",
        "        axes[j].set_xlabel(f'steps', fontsize=20)\n",
        "        axes[j].set_ylabel(f'E', fontsize=20)\n",
        "        display.clear_output(wait=True)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJbMS_sd--vo",
        "colab_type": "text"
      },
      "source": [
        "The minimal energy is $2L^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj4_-LChLMin",
        "colab_type": "text"
      },
      "source": [
        "# Thermodynamic constants at different temperatures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLK2kJOWwLwR",
        "colab_type": "text"
      },
      "source": [
        "Until now we only trained as CRBM at a $T=1$. Train differnt CRBM at different $T$s.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D45rMFAJLR8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(T, crbm=None):\n",
        "    if crbm is None:\n",
        "        crbm = CRBM(filter_dims=(2, 2))\n",
        "    \n",
        "    l_train = 10 ** 9\n",
        "    l_test = 10 ** 9\n",
        "    epoch = 0\n",
        "    while l_train > 10 ** -4:\n",
        "        # train\n",
        "        l_train = 0\n",
        "\n",
        "        for train_s, train_E in train_dataset:\n",
        "            l_train += crbm.train(train_s, train_E / T)\n",
        "        \n",
        "        l_train = l_train / N_TRAIN_BATCHES\n",
        "\n",
        "        # plot results\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            l_test = crbm.compute_loss(states_test, E_phys_test / T)\n",
        "\n",
        "            display.clear_output()\n",
        "\n",
        "            print(\n",
        "                f\"Temp: {T} | Epoch: {epoch} | loss test: {l_test}| loss train: {l_train}\"\n",
        "            )\n",
        "        epoch += 1\n",
        "   \n",
        "    return crbm   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fVXXJsbxRhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ts = np.linspace(1.5, 3.5, 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKA6BFdb9n32",
        "colab_type": "text"
      },
      "source": [
        "Train different CRBM's at different temperatures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X4-M258w5kI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%time\n",
        "#crbms = [train(T) for T in Ts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EpzESjt8tYj",
        "colab_type": "text"
      },
      "source": [
        "Faster. Train a CRBM at a temperature, save it, and then modify it's temperature and retrain it at the new temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou7tzktTThL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "crbm = CRBM(filter_dims=(2, 2))\n",
        "crbms = []\n",
        "T_old = Ts[0]\n",
        "for T in Ts:\n",
        "    crbm_new = CRBM(filter_dims=(2, 2))\n",
        "    \n",
        "    crbm_new.W.assign(crbm.W / T * T_old )\n",
        "    crbm_new.vbias.assign(crbm.vbias / T * T_old)\n",
        "    crbm_new.hbias.assign(crbm.hbias / T * T_old)\n",
        "    \n",
        "    W_old = crbm_new.W.numpy()\n",
        "    crbm = train(T, crbm_new)\n",
        "    W_new = crbm.W.numpy()\n",
        "    \n",
        "    crbms.append(crbm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-8wCYOXEl6e",
        "colab_type": "text"
      },
      "source": [
        "# Montecarlo Simulations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aon4yyLvEsDM",
        "colab_type": "text"
      },
      "source": [
        "The functions performs gibbs steps with a CRBM and saves the energy and magnetization in arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIz4HrfXyCX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MC(crbm, states, steps, hidden_steps=10):\n",
        "    Es = np.empty(steps)\n",
        "    Ms = np.empty(steps)\n",
        "    \n",
        "    for i in range(steps):\n",
        "        states = crbm.gibbs_k(states, k=hidden_steps)\n",
        "        \n",
        "        # Get the state out of the gpu\n",
        "        state_np = states.numpy()\n",
        "        Es[i] = ising_energy(state_np)[0]\n",
        "        Ms[i] = (2 * state_np - 1).sum()\n",
        "              \n",
        "    return Es, Ms, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiAgoIsXEXa3",
        "colab_type": "text"
      },
      "source": [
        "This function will plot the thermodynamic constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WxXnDVh06Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_thermodynamics(Temp, Es, Cvs, mag, susceptibility):\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Plot the Energy, Magnetization, Specific Heat and Susceptibility\n",
        "    # ----------------------------------------------------------------------\n",
        "\n",
        "    f = plt.figure(figsize=(18, 10), dpi=80, facecolor='w', edgecolor='k')\n",
        "    xlabel = \"T\"\n",
        "    \n",
        "    sp = f.add_subplot(2, 2, 1)\n",
        "    plt.xlabel(xlabel, fontsize=20)\n",
        "    plt.ylabel(\"Energy \", fontsize=20)\n",
        "    plt.scatter(Temp, Es)\n",
        "\n",
        "    sp = f.add_subplot(2, 2, 2)\n",
        "    plt.xlabel(xlabel, fontsize=20)\n",
        "    plt.ylabel(\"Magnetization \", fontsize=20)\n",
        "    plt.scatter(Temp, mag)\n",
        "\n",
        "    sp = f.add_subplot(2, 2, 3)\n",
        "    plt.xlabel(xlabel, fontsize=20)\n",
        "    plt.ylabel(\"Specific Heat \", fontsize=20)\n",
        "\n",
        "    plt.scatter(Temp, Cvs)\n",
        "    plt.axvline(x=2.269)\n",
        "\n",
        "    sp = f.add_subplot(2, 2, 4);\n",
        "    plt.xlabel(xlabel, fontsize=20);\n",
        "    plt.ylabel(\"Susceptibility\", fontsize=20);\n",
        "    \n",
        "    plt.scatter(Temp, susceptibility)\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH35rZQhFSI2",
        "colab_type": "text"
      },
      "source": [
        "Initialize the step that will be used during the MC. There is an oportunity for parallelization in the Gpu if severall states are updated in the simulation. For simplicity only one states is used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2FSWc2ImNI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L = 25\n",
        "states = tf.random.uniform((1, L, L, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTbe0Ya6Fa6Q",
        "colab_type": "text"
      },
      "source": [
        "We start with the highest temperature and slowly lower it. First there is a warmup phase and then thermodynamic constants are recorded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_krDMaEex-MW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "energy = []\n",
        "magnetization = []\n",
        "CV = []\n",
        "susceptibility = []\n",
        "\n",
        "e, m, states = MC(crbms[-1], states, 2 * 10 ** 4)\n",
        "for i, crbm in enumerate(crbms[::-1]):\n",
        "    # Warmup\n",
        "    e, m, states = MC(crbm, states, 10 ** 3)\n",
        "    \n",
        "    # Mc Simulation\n",
        "    e, m, states = MC(crbm, states,  2 * 10 ** 4)\n",
        "    \n",
        "    # Computing expectaion values\n",
        "    e1 = e.mean()\n",
        "    e2 = (e ** 2).mean()\n",
        "    \n",
        "    m1 = m.mean()\n",
        "    m2 = (m ** 2).mean()\n",
        "    \n",
        "    \n",
        "    energy.append(e1 / L ** 2)\n",
        "    magnetization.append(m1 / L ** 2)\n",
        "    CV.append( (e2 - e1 ** 2) / Ts[-i - 1] ** 2 / L ** 2 )\n",
        "    susceptibility.append( (m2 - m1 ** 2) / Ts[-i - 1] / L ** 2 )\n",
        "    \n",
        "    \n",
        "    display.clear_output()\n",
        "    print(\"Temp: \", Ts[-i -1])\n",
        "    plt.imshow(states.numpy()[0, :, :, 0], vmin=0, vmax=1, cmap=\"gray\")\n",
        "    plt.show()\n",
        "    \n",
        "    # Plot thermodynamics\n",
        "    plot_thermodynamics(Ts[-i - 1:], energy[::-1], CV[::-1], magnetization[::-1], susceptibility[::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmlMWCl2eC13",
        "colab_type": "text"
      },
      "source": [
        "Above you can see that the Magnetization colapses to 0 after the critical temperature $T_c=2.269$ and that the specific heat is maximal around $T_c$ as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m5rUr7eFHk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEcPyQpDPtQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(t1 - t0) / 60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hk388DSV6WT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}