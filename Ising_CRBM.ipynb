{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ising CRBM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielalcalde/MCMC_CRBM/blob/master/Ising_CRBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amXB-OcpSa1R",
        "colab_type": "text"
      },
      "source": [
        "# Simulating the Ising model using an CRBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0xxh6USSodO",
        "colab_type": "text"
      },
      "source": [
        "## Abstract:\n",
        "Machine learning is becoming widely used in analyzing the thermodynamics of many-body condensed matter systems.\n",
        "Restricted Boltzmann Machine (RBM) aided Montecarlo simulations have sparked interest recently as they manage to speed up classical Monte Carlo simulations.\n",
        "Here we employ the Convolutional Restricted Boltzmann Machine (CRBM) method and show that its use helps to reduce the number of parameters to be learned drastically by taking advantage of translation invariance. Furthermore, we show that it is possible to train the CRBM at smaller lattice sizes, and apply it to bigger lattice sizes. To demonstrate the efficiency of CRBM we apply it to the paradigmatic  Ising and Kitaev models in two dimensions.\n",
        "\n",
        "## Paper:\n",
        "paper link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaiBKOtWTBEV",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "This Notebook is intended as an educational tool for the use of Convolutional Restricted Boltzmann Machines in classical Montecarlo simulations. The code for the paper was written with the library Theano, which will no longer be updated, that is why we have chosen to present the main concept in TensorFlow. Specifically, this notebook only tackles the Ising model. As there is only the nearest neighbor interaction, we can teach the CRBM using 3X3 states, this has as a consequence that we are able to generate all possible states $2^{3*3}= 512$ and learn the energy function from them. So no Metropolis is necessary, and no sampling of the CRBM while training is necessary. Also contrary to the main work, for simplicity, no correction step or parallel tempering is introduced. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t5AMJk__vdw",
        "colab_type": "text"
      },
      "source": [
        "# Installing tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqVmIoHumhCe",
        "colab_type": "code",
        "outputId": "ff3978ec-80ab-454c-bd0d-2c84b754b053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "### install necessary packages if in colab\n",
        "def run_subprocess_command(cmd):\n",
        "    process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
        "    for line in process.stdout:\n",
        "        print(line.decode().strip())\n",
        "\n",
        "\n",
        "import sys, subprocess\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "colab_requirements = [\"pip install tensorflow-gpu==2.0.0-beta1\"]\n",
        "if IN_COLAB:\n",
        "    for i in colab_requirements:\n",
        "        run_subprocess_command(i)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0-beta1 in /usr/local/lib/python3.6/dist-packages (2.0.0b1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (3.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.16.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0a20190603)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.33.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-beta1) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta1) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzkLSnOF_4EG",
        "colab_type": "text"
      },
      "source": [
        "# Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTbdHbRCoJzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adjL1Ta-4yjG",
        "colab_type": "text"
      },
      "source": [
        "Accuracy used for training and numerics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mYviS_74wT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "floatX = np.float32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdJQe7e7PmE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t0 = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6CGNL5T__7Q",
        "colab_type": "text"
      },
      "source": [
        "# Helping functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMdm-89o52rP",
        "colab_type": "text"
      },
      "source": [
        "Tensorflow has no implementation of the binomial function. With help of random.uniform the beahviour can be replicated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuZ3rWnuorPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binomial(means):\n",
        "    return (tf.sign(means - tf.random.uniform(tf.shape(means))) + 1 )/2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRYigXZ33_SS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7a8fff5-39e4-411d-a657-60ba928a4341"
      },
      "source": [
        "binomial(np.array([0.5, 0.5, 0.1, 0.9]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=14, shape=(4,), dtype=float32, numpy=array([1., 1., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8rR10bN6WBI",
        "colab_type": "text"
      },
      "source": [
        "This functions creates periodic padding so that the convolution has periodic boundary conditions. When performing the transposed convolution step the padding is placed in the oposite site then for the convolution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWbNnXjOng1d",
        "colab_type": "code",
        "outputId": "e9e12eaa-797d-45ff-df03-12a9dc049635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "def periodic_padding(x, filter_size=2, deconv=False):\n",
        "    '''\n",
        "    x: shape (batch_size, d1, d2)\n",
        "    return x padded with periodic boundaries. i.e. torus or donut\n",
        "    '''\n",
        "    pad_r = filter_size // 2\n",
        "    pad_l = filter_size - pad_r - 1\n",
        "    \n",
        "    d1, d2 = x.shape[1:3]\n",
        "    \n",
        "    # When deconvolving the pading should reverses\n",
        "    if deconv:\n",
        "        p = pad_r\n",
        "        pad_r = pad_l\n",
        "        pad_l = p   \n",
        "\n",
        "    top_left = x[:, d1 - pad_l:, d2 - pad_l:]\n",
        "    top_center = x[:, d1 - pad_l:, :]\n",
        "    top_right = x[:, d1 - pad_l:, :pad_r]\n",
        "\n",
        "    middle_left = x[:, :, d2 - pad_l:]\n",
        "    middle_center = x\n",
        "    middle_right = x[:, :, :pad_r]\n",
        "\n",
        "    bottom_left = x[:, :pad_r, d2 - pad_l:]\n",
        "    bottom_center = x[:, :pad_r, :]\n",
        "    bottom_right = x[:, :pad_r, :pad_r]\n",
        "    \n",
        "    top = tf.concat([top_left, top_center, top_right], axis=2)\n",
        "    middle = tf.concat([middle_left, middle_center, middle_right], axis=2)\n",
        "    bottom = tf.concat([bottom_left, bottom_center, bottom_right], axis=2)\n",
        "    padded_x = tf.concat([top, middle, bottom], axis=1)\n",
        "    return padded_x\n",
        "\n",
        "a = tf.Variable(np.arange(4 * 4).reshape(1, 4, 4))\n",
        "print(a)\n",
        "print(periodic_padding(a))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(1, 4, 4) dtype=int64, numpy=\n",
            "array([[[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11],\n",
            "        [12, 13, 14, 15]]])>\n",
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  0]\n",
            "  [ 4  5  6  7  4]\n",
            "  [ 8  9 10 11  8]\n",
            "  [12 13 14 15 12]\n",
            "  [ 0  1  2  3  0]]], shape=(1, 5, 5), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ba-8XzQve8c",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85mAzBWlt7p7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_int(x):\n",
        "    if x =='0' or x == '1': return int(x)\n",
        "    else: return 0\n",
        "\n",
        "#This will generate all posible NXN matrices with {0,1}^(NXN) don't use with more then N=4\n",
        "def bit_string(N):\n",
        "    maxim = 2 ** (N ** 2)\n",
        "    a = np.asarray([[to_int(x) for x in list(('{0:' + str(N ** 2) + 'b}').format(i))] for i in range(maxim)], dtype=floatX)\n",
        "    return a.reshape(2 ** (N ** 2), N, N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m19Njkt2AJsT",
        "colab_type": "text"
      },
      "source": [
        "Generate all posible 3X3 states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5IEPtsTvUIa",
        "colab_type": "code",
        "outputId": "51de02ae-dea8-4f34-e65f-d817f7643b58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "states_train = bit_string(3)[:, :, :, None]\n",
        "states_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 3, 3, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOS0L2tAATVe",
        "colab_type": "text"
      },
      "source": [
        "Generate a random test set of lattice size N=10 to evaluate if the CRBM matches the ISing model for bigger lattice sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4t-Mm4E1ur4",
        "colab_type": "code",
        "outputId": "85367999-87f4-4677-c757-a9da01b44874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "N = 50\n",
        "states_test = np.asarray(np.random.binomial(size=(4 * 10 ** 3, N, N, 1), p=0.5, n=1), dtype=floatX)\n",
        "states_test.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 50, 50, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1CTzY8LvrPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ising_energy(states):\n",
        "    states = 2 * states - 1\n",
        "\n",
        "    nb = np.roll(states, shift=-1, axis=1) + np.roll(states, shift=-1, axis=2)\n",
        "\n",
        "    return -np.sum(states * nb, axis=(1, 2, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31kyXyzxAteM",
        "colab_type": "text"
      },
      "source": [
        "For now we will only consider the case $T=1$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DwA8L7N2XbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoCi0HL2A16p",
        "colab_type": "text"
      },
      "source": [
        "The physical energy is computed for train and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ny3qOL3vl3O",
        "colab_type": "code",
        "outputId": "86a7d679-3f3e-46cb-a8df-e9de4eb9932b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "E_phys_train = ising_energy(states_train)\n",
        "E_phys_test = ising_energy(states_test)\n",
        "E_phys_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ0t1lhZBB4c",
        "colab_type": "text"
      },
      "source": [
        "The CRBm will be trained by batches of 32 states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSZRLeNDwxuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUF = E_phys_train.shape[0]\n",
        "BATCH_SIZE = 2 ** 5\n",
        "N_TRAIN_BATCHES = TRAIN_BUF// BATCH_SIZE\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((states_train, E_phys_train / temp)).shuffle(TRAIN_BUF).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5nHB6wC03au",
        "colab_type": "code",
        "outputId": "ce773578-db9b-489d-e42c-94ae62057052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "2 ** 5"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BzB92R0zgqs",
        "colab_type": "text"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxSkWptE0hXI",
        "colab_type": "text"
      },
      "source": [
        "Initialize the kernel W with filter_dims=(filter_number, filter_size) and both biases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0H-WBKOx1Lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_dims = (2, 2)\n",
        "filter_shape = (filter_dims[1], filter_dims[1], 1, filter_dims[0])\n",
        "\n",
        "\n",
        "multi = np.prod(filter_shape)\n",
        "W_np = np.asarray(np.random.randn(*filter_shape) * np.sqrt(2 / multi), dtype=floatX)\n",
        "\n",
        "W = tf.Variable(W_np)\n",
        "\n",
        "vbias = tf.Variable(np.zeros(1, dtype=floatX))\n",
        "hbias = tf.Variable(np.zeros(filter_dims[0], dtype=floatX))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6CTcpub1Dd8",
        "colab_type": "text"
      },
      "source": [
        "The negative log likelihood also called free-energy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYuxQcKzx5cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def n_log_like(v):\n",
        "    input4D = periodic_padding(v, filter_dims[1])\n",
        "    filters4D = W\n",
        "\n",
        "    # Convolution\n",
        "    out = tf.nn.conv2d(input4D, filters4D, strides=1, padding=\"VALID\")\n",
        "    out = hbias[None, None, None, :] + out\n",
        "\n",
        "    # Same as softplus(x)=log(1 + exp(x))\n",
        "    hidden_term_not = tf.math.softplus(out)\n",
        "    hidden_term = tf.reduce_sum(hidden_term_not, axis=(1, 2, 3))\n",
        "\n",
        "    visible_term = tf.reduce_sum(v, axis=(1, 2)) * vbias[None, :]\n",
        "    visible_term = tf.reduce_sum(visible_term, axis=1)\n",
        "\n",
        "    return -hidden_term - visible_term"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXdCNfJ_1dGb",
        "colab_type": "text"
      },
      "source": [
        "$P(h|x): x \\rightarrow h$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EPUk1rvyAI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prop_vis_to_hid(v):\n",
        "    input4D = periodic_padding(v, filter_dims[1])\n",
        "    filters4D = W\n",
        "\n",
        "    # Convolution\n",
        "    out = tf.nn.conv2d(input4D, filters4D, strides=1, padding=\"VALID\")\n",
        "\n",
        "    out = hbias[None, None, None, :] + out\n",
        "\n",
        "    mean_activation = tf.math.sigmoid(out)\n",
        "    return binomial(mean_activation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxXeic0n2Cft",
        "colab_type": "text"
      },
      "source": [
        "$P(x|h): h \\rightarrow x$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0s652fiyHR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prop_hid_to_vis(h):\n",
        "    input4D = periodic_padding(h, filter_dims[1], deconv=True)\n",
        "    filters4D = tf.transpose(W[::-1, ::-1], [0, 1, 3, 2])\n",
        "\n",
        "    # Convolution\n",
        "    out = tf.nn.conv2d(input4D, filters4D, strides=1, padding=\"VALID\")\n",
        "\n",
        "    out = vbias[None, None, None, :] + out\n",
        "\n",
        "    mean_activation = tf.math.sigmoid(out)\n",
        "    return binomial(mean_activation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKCCahXU2Nj_",
        "colab_type": "text"
      },
      "source": [
        "$P(x'|x): x \\rightarrow x'$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDEsrO92yN3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gibbs(state):\n",
        "    return prop_hid_to_vis(prop_vis_to_hid(state))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvZzNjW_2W2_",
        "colab_type": "text"
      },
      "source": [
        "$diff(x) = E(x) - F(x)$ \\\\\n",
        "$C = \\sum_x diff(x)$ \\\\\n",
        "$loss = \\sum_x (diff(x) - C)^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "expppT3Qyc48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def compute_loss(x, nll_phys):\n",
        "    nll_crbm = n_log_like(x)\n",
        "\n",
        "    diff = nll_phys - nll_crbm\n",
        "    C = tf.reduce_mean(diff)\n",
        "\n",
        "    loss = tf.reduce_mean((diff - C) ** 2)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tazcvUJ3b4D",
        "colab_type": "text"
      },
      "source": [
        "Initialize the adam optimizer, compute the gradients and apply them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ctvr0eLymUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = tf.keras.optimizers.Adam()\n",
        "def compute_grad(x, nll_phys):\n",
        "    # compute the grad\n",
        "\n",
        "    ### pass through network\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = compute_loss(x, nll_phys)\n",
        "\n",
        "    grad = tape.gradient(loss, params)\n",
        "    return grad, loss\n",
        "\n",
        "@tf.function\n",
        "def train(x, nll_phys):\n",
        "    grad, loss = compute_grad(x, nll_phys)\n",
        "\n",
        "    opt.apply_gradients(zip(grad, params))\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2mNJF1ixnN4",
        "colab_type": "text"
      },
      "source": [
        "Everything combined in one Class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu2rPLnOmrjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CRBM:\n",
        "        def __init__(\n",
        "        self,\n",
        "        filter_dims=(2, 2),\n",
        "        opt=None\n",
        "\n",
        "    ):\n",
        "            assert len(filter_dims) == 2\n",
        "            if opt is None:\n",
        "                opt = tf.keras.optimizers.Adam()\n",
        "                \n",
        "            self.opt = opt\n",
        "            \n",
        "            self.filter_shape = (filter_dims[1], filter_dims[1], 1, filter_dims[0])\n",
        "            self.filter_dims = filter_dims\n",
        "\n",
        "\n",
        "            multi = np.prod(self.filter_shape)\n",
        "            W_np = np.asarray(np.random.randn(*self.filter_shape) * np.sqrt(2 / multi), dtype=floatX)\n",
        "\n",
        "            W = tf.Variable(W_np)\n",
        "\n",
        "            vbias = tf.Variable(np.zeros(1, dtype=floatX))\n",
        "            hbias = tf.Variable(np.zeros(filter_dims[0], dtype=floatX))\n",
        "\n",
        "            self.W = W\n",
        "            self.hbias = hbias\n",
        "            self.vbias = vbias\n",
        "\n",
        "\n",
        "            # Learning parameters\n",
        "            self.params = [self.W, self.vbias, self.hbias]\n",
        "\n",
        "\n",
        "        def n_log_like(self, v):\n",
        "            input4D = periodic_padding(v, self.filter_dims[1])\n",
        "            filters4D = self.W\n",
        "\n",
        "            # Convolution\n",
        "            out = tf.nn.conv2d(input4D, filters4D, strides=1, padding=\"VALID\")\n",
        "            out = self.hbias[None, None, None, :] + out\n",
        "\n",
        "            # Same as softplus(x)=log(1 + exp(x))\n",
        "            hidden_term_not = tf.math.softplus(out)\n",
        "            hidden_term = tf.reduce_sum(hidden_term_not, axis=(1, 2, 3))\n",
        "\n",
        "            visible_term = tf.reduce_sum(v, axis=(1, 2)) * self.vbias[None, :]\n",
        "            visible_term = tf.reduce_sum(visible_term, axis=1)\n",
        "\n",
        "            return -hidden_term - visible_term\n",
        "\n",
        "        def prop_vis_to_hid(self, v):\n",
        "            input4D = periodic_padding(v, self.filter_dims[1])\n",
        "            filters4D = self.W\n",
        "            \n",
        "            # Convolution\n",
        "            out = tf.nn.conv2d(input4D, filters4D, strides=1, padding=\"VALID\")\n",
        "            \n",
        "            out = self.hbias[None, None, None, :] + out\n",
        "            \n",
        "            mean_activation = tf.math.sigmoid(out)\n",
        "            return binomial(mean_activation)\n",
        "            \n",
        "        \n",
        "        def prop_hid_to_vis(self, h):\n",
        "            input4D = periodic_padding(h, self.filter_dims[1], deconv=True)\n",
        "            filters4D = tf.transpose(self.W[::-1, ::-1], [0, 1, 3, 2])\n",
        "\n",
        "            # Convolution\n",
        "            out = tf.nn.conv2d(input4D, filters4D, strides=1, padding=\"VALID\")\n",
        "            \n",
        "            out = self.vbias[None, None, None, :] + out\n",
        "            \n",
        "            mean_activation = tf.math.sigmoid(out)\n",
        "            return binomial(mean_activation)\n",
        "        \n",
        "        @tf.function\n",
        "        def gibbs(self, state):\n",
        "            return self.prop_hid_to_vis(self.prop_vis_to_hid(state))\n",
        "        \n",
        "        \n",
        "        @tf.function\n",
        "        def gibbs_k(self, state, k=1):\n",
        "            \n",
        "            i = tf.constant(0)\n",
        "            cond = lambda i, state: tf.less(i, k)\n",
        "\n",
        "            def operation(i, state):\n",
        "                i += 1\n",
        "                state = self.gibbs(state)\n",
        "                return i, state\n",
        "\n",
        "            state = tf.while_loop(cond, operation, [i, state])\n",
        "            \n",
        "            return state\n",
        "        \n",
        "        @tf.function\n",
        "        def compute_loss(self, x, nll_phys):\n",
        "            nll_crbm = self.n_log_like(x)\n",
        "\n",
        "            diff = nll_phys - nll_crbm\n",
        "            C = tf.reduce_mean(diff)\n",
        "            \n",
        "            loss = tf.reduce_mean((diff - C) ** 2)\n",
        "            return loss\n",
        "        \n",
        "        def compute_grad(self, x, nll_phys):\n",
        "            # compute the grad\n",
        "\n",
        "            ### pass through network\n",
        "            with tf.GradientTape() as tape:\n",
        "                loss = self.compute_loss(x, nll_phys)\n",
        "\n",
        "            grad = tape.gradient(loss, self.params)\n",
        "            return grad, loss\n",
        "    \n",
        "\n",
        "        @tf.function\n",
        "        def train(self, x, nll_phys):\n",
        "            grad, loss = self.compute_grad(x, nll_phys)\n",
        "\n",
        "            self.opt.apply_gradients(zip(grad, self.params))\n",
        "            return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMFUHQ7hyNXR",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ylnigpuBSB9",
        "colab_type": "text"
      },
      "source": [
        "We create an object CRBM and train it. One can see that both the train_loss and the test_loss decrease simulaniously. The expected difference between the two losses should be around $\\frac{t_{test}}{t_{train}}=\\frac{N_{test}^2}{N^2_{train}}=\\frac{50^2}{3^2}=277.77$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpvy_HS-vrMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crbm = CRBM(filter_dims=(2, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Luj353ygYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train = []\n",
        "loss_test = []\n",
        "epoch = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmVULw63xiGi",
        "colab_type": "code",
        "outputId": "8a3bd231-fa8f-47e5-d876-655fd7937bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "%%time\n",
        "l_train = 10 ** 9\n",
        "l_test = 10 ** 9\n",
        "\n",
        "while l_train > 10 ** -4:\n",
        "    # train\n",
        "    l_train = 0\n",
        "    \n",
        "    for train_s, train_E in train_dataset:\n",
        "        l_train += crbm.train(train_s, train_E)\n",
        "    \n",
        "    \n",
        "    l_train = l_train / N_TRAIN_BATCHES\n",
        "    #for test_x, test_y in tqdm(test_ds, total=N_TEST_BATCHES):\n",
        "    #l_test, acc_test = mps.compute_loss_accuracy(x_test, y_test)\n",
        "        \n",
        "    # plot results\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "        l_test = crbm.compute_loss(states_test, E_phys_test)\n",
        "        \n",
        "        loss_train.append(l_train) \n",
        "        loss_test.append(l_test)\n",
        "        \n",
        "        display.clear_output()\n",
        "\n",
        "        print(\n",
        "            f\"Epoch: {epoch} | loss test: {loss_test[-1]}| loss train: {loss_train[-1]}| ltest/ltrain: {loss_test[-1]/loss_train[-1]}\"\n",
        "        )\n",
        "        plt.plot(loss_train)\n",
        "        plt.plot(loss_test)\n",
        "        plt.yscale(\"log\")\n",
        "        plt.show()\n",
        "    epoch += 1"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3200 | loss test: 0.027201000601053238| loss train: 0.00010003904753830284| ltest/ltrain: 271.9038391113281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf2e9coKx407uAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 54s, sys: 12.3 s, total: 2min 6s\n",
            "Wall time: 1min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBaalL7QRmEn",
        "colab_type": "text"
      },
      "source": [
        "The learned convolutional filters show the effective interaction between nearest neighbours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBc3oN6q41eB",
        "colab_type": "code",
        "outputId": "1a993048-c1c3-4585-f3e6-5e580a16d180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "W = crbm.W.numpy()\n",
        "vmax = np.max(abs(W))\n",
        "\n",
        "\n",
        "f = plt.figure(figsize=(5, 10), dpi=80, facecolor='w', edgecolor='k')\n",
        "\n",
        "f.add_subplot(1, 2, 1)\n",
        "plt.imshow(W[:, :,0, 0], vmin =-vmax, vmax=vmax, cmap=\"seismic\")\n",
        "f.add_subplot(1, 2, 2)\n",
        "\n",
        "plt.imshow(W[:,: ,0, 1], vmin =-vmax, vmax=vmax, cmap=\"seismic\")\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAACyCAYAAAC0jP8KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxShxALAYJQ4AFqPEAcBi/weokyW5x586PgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 400x800 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mZoKqjr7uVT",
        "colab_type": "text"
      },
      "source": [
        "# Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVHIsquKZoh1",
        "colab_type": "text"
      },
      "source": [
        "A state with $N=50$ is updated $10 ^4$ times using gibbs sampling.  Because the temperature T=1, is well bellow the critical temperature TC=2.269 it converges to the ground state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30z8c8PT7JLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 50\n",
        "states = tf.random.uniform((1, N, N, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsODKWM66otO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 3 * 10 ** 4\n",
        "Es = []\n",
        "for i in range(epochs):\n",
        "    states = crbm.gibbs(states)\n",
        "    Es.append(ising_energy(states)[0])\n",
        "    \n",
        "    if i % 500 == 0:\n",
        "        display.clear_output()\n",
        "        plt.imshow(states.numpy()[0, :,:, 0], vmin=0, vmax=1, cmap=\"gray\")\n",
        "        plt.show()\n",
        "        plt.plot(Es)\n",
        "        plt.plot([0, len(Es)], [-2 * N**2, -2 * N**2])\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJbMS_sd--vo",
        "colab_type": "text"
      },
      "source": [
        "The minimat energy is N^2 * 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj4_-LChLMin",
        "colab_type": "text"
      },
      "source": [
        "# Thermodynamic constants at different temperatures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLK2kJOWwLwR",
        "colab_type": "text"
      },
      "source": [
        "Until now we only trained as CRBM at a $T=1$. Train differnt CRBM at different $T$s.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D45rMFAJLR8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(T, crbm=None):\n",
        "    if crbm is None:\n",
        "        crbm = CRBM(filter_dims=(2, 2))\n",
        "    \n",
        "    l_train = 10 ** 9\n",
        "    l_test = 10 ** 9\n",
        "    epoch = 0\n",
        "    while l_train > 10 ** -4:\n",
        "        # train\n",
        "        l_train = 0\n",
        "\n",
        "        for train_s, train_E in train_dataset:\n",
        "            l_train += crbm.train(train_s, train_E / T)\n",
        "        \n",
        "        l_train = l_train / N_TRAIN_BATCHES\n",
        "\n",
        "        # plot results\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            l_test = crbm.compute_loss(states_test, E_phys_test / T)\n",
        "\n",
        "            display.clear_output()\n",
        "\n",
        "            print(\n",
        "                f\"Temp: {T} | Epoch: {epoch} | loss test: {l_test}| loss train: {l_train}\"\n",
        "            )\n",
        "        epoch += 1\n",
        "   \n",
        "    return crbm   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fVXXJsbxRhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ts = np.linspace(1.5, 3.5, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKA6BFdb9n32",
        "colab_type": "text"
      },
      "source": [
        "Train different CRBM's at different temperatures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X4-M258w5kI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%time\n",
        "#crbms = [train(T) for T in Ts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EpzESjt8tYj",
        "colab_type": "text"
      },
      "source": [
        "Faster. Train a CRBM at a temperature, save it, and then modify it's temperature and retrain it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou7tzktTThL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "crbm = CRBM(filter_dims=(2, 2))\n",
        "crbms = []\n",
        "T_old = Ts[0]\n",
        "for T in Ts:\n",
        "    crbm_new = CRBM(filter_dims=(2, 2))\n",
        "    \n",
        "    crbm_new.W.assign(crbm.W / T * T_old )\n",
        "    crbm_new.vbias.assign(crbm.vbias / T * T_old)\n",
        "    crbm_new.hbias.assign(crbm.hbias / T * T_old)\n",
        "    \n",
        "    W_old = crbm_new.W.numpy()\n",
        "    crbm = train(T, crbm_new)\n",
        "    W_new = crbm.W.numpy()\n",
        "    \n",
        "    crbms.append(crbm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-8wCYOXEl6e",
        "colab_type": "text"
      },
      "source": [
        "# Montecarlo Simulations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aon4yyLvEsDM",
        "colab_type": "text"
      },
      "source": [
        "The functions performs gibbs steps with a CRBM and saves the energy and magnetization in arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIz4HrfXyCX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MC(crbm, states, steps, hidden_steps=10):\n",
        "    Es = np.empty(steps)\n",
        "    Ms = np.empty(steps)\n",
        "    \n",
        "    for i in range(steps):\n",
        "        states = crbm.gibbs_k(states, k=hidden_steps)\n",
        "        \n",
        "        # Get the state out of the gpu\n",
        "        state_np = states.numpy()\n",
        "        Es[i] = ising_energy(state_np)[0]\n",
        "        Ms[i] = (2 * state_np - 1).sum()\n",
        "              \n",
        "    return Es, Ms, states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiAgoIsXEXa3",
        "colab_type": "text"
      },
      "source": [
        "This function will plot the thermodynamic constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WxXnDVh06Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_thermodynamics(Temp, Es, Cvs, mag, susceptibility):\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Plot the Energy, Magnetization, Specific Heat and Susceptibility\n",
        "    # ----------------------------------------------------------------------\n",
        "\n",
        "    f = plt.figure(figsize=(18, 10), dpi=80, facecolor='w', edgecolor='k')\n",
        "    xlabel = \"T\"\n",
        "    \n",
        "    sp = f.add_subplot(2, 2, 1)\n",
        "    plt.xlabel(xlabel, fontsize=20)\n",
        "    plt.ylabel(\"Energy \", fontsize=20)\n",
        "    plt.scatter(Temp, Es)\n",
        "\n",
        "    sp = f.add_subplot(2, 2, 2)\n",
        "    plt.xlabel(xlabel, fontsize=20)\n",
        "    plt.ylabel(\"Magnetization \", fontsize=20)\n",
        "    plt.scatter(Temp, mag)\n",
        "\n",
        "    sp = f.add_subplot(2, 2, 3)\n",
        "    plt.xlabel(xlabel, fontsize=20)\n",
        "    plt.ylabel(\"Specific Heat \", fontsize=20)\n",
        "\n",
        "    plt.scatter(Temp, Cvs)\n",
        "    plt.axvline(x=2.269)\n",
        "\n",
        "    sp = f.add_subplot(2, 2, 4);\n",
        "    plt.xlabel(xlabel, fontsize=20);\n",
        "    plt.ylabel(\"Susceptibility\", fontsize=20);\n",
        "    \n",
        "    plt.scatter(Temp, susceptibility)\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH35rZQhFSI2",
        "colab_type": "text"
      },
      "source": [
        "Initialize the step that will be used during the MC. There is an oportunity for parallelization in the Gpu if severall states are updated in the simulation. For simplicity only one states is used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2FSWc2ImNI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 25\n",
        "states = tf.random.uniform((1, N, N, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTbe0Ya6Fa6Q",
        "colab_type": "text"
      },
      "source": [
        "We start with the highest temperature and slowly lower it. First there is a warmup phase and then thermodynamic constants are recorded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_krDMaEex-MW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "energy = []\n",
        "magnetization = []\n",
        "CV = []\n",
        "susceptibility = []\n",
        "\n",
        "e, m, states = MC(crbms[-1], states, 2 * 10 ** 4)\n",
        "for i, crbm in enumerate(crbms[::-1]):\n",
        "    # Warmup\n",
        "    e, m, states = MC(crbm, states, 10 ** 3)\n",
        "    \n",
        "    # Mc Simulation\n",
        "    e, m, states = MC(crbm, states,  2 * 10 ** 4)\n",
        "    \n",
        "    # Computing expectaion values\n",
        "    e1 = e.mean()\n",
        "    e2 = (e ** 2).mean()\n",
        "    \n",
        "    m1 = m.mean()\n",
        "    m2 = (m ** 2).mean()\n",
        "    \n",
        "    \n",
        "    energy.append(e1 / N ** 2)\n",
        "    magnetization.append(m1 / N ** 2)\n",
        "    CV.append( (e2 - e1 ** 2) / Ts[-i - 1] ** 2 / N ** 2 )\n",
        "    susceptibility.append( (m2 - m1 ** 2) / Ts[-i - 1] / N ** 2 )\n",
        "    \n",
        "    \n",
        "    display.clear_output()\n",
        "    print(\"Temp: \", Ts[-i -1])\n",
        "    plt.imshow(states.numpy()[0, :, :, 0], vmin=0, vmax=1, cmap=\"gray\")\n",
        "    plt.show()\n",
        "    \n",
        "    # Plot thermodynamics\n",
        "    plot_thermodynamics(Ts[-i - 1:], energy[::-1], CV[::-1], magnetization[::-1], susceptibility[::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmlMWCl2eC13",
        "colab_type": "text"
      },
      "source": [
        "Above you can see that the Magnetization colapses to 0 after the critical temperature $T_c=2.269$ and that the specific heat is maximal around $T_c$ as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m5rUr7eFHk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEcPyQpDPtQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(t1 - t0) / 60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hk388DSV6WT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}